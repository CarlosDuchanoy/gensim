{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of FastText and Word2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook Research open sourced a great project yesterday - [fastText](https://github.com/facebookresearch/fastText), a fast (no surprise) and effective method to learn word representations and perform text classification. I was curious about comparing these embeddings to other commonly used embeddings, so word2vec seemed like the obvious choice, especially considering fastText embeddings are an extension of word2vec. \n",
    "\n",
    "I've used gensim to train the word2vec models, and the analogical reasoning task (described in Section 4.1 of [[2]](https://arxiv.org/pdf/1301.3781v3.pdf)) for comparing the word2vec and fastText models. I've compared embeddings trained using the skipgram architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download() \n",
    "# Only the brown corpus is needed in case you don't have it.\n",
    "# alternately, you can simply download the pretrained models below if you wish to avoid downloading and training\n",
    "\n",
    "# Generate brown corpus text file\n",
    "with open('brown_corp.txt', 'w+') as f:\n",
    "    for word in nltk.corpus.brown.words():\n",
    "        f.write('{word} '.format(word=word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download the text8 corpus (a 100 MB sample of cleaned wikipedia text)\n",
    "# alternately, you can simply download the pretrained models below if you wish to avoid downloading and training\n",
    "!wget http://mattmahoney.net/dc/text8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download the file questions-words.txt to be used for comparing word embeddings\n",
    "!wget https://raw.githubusercontent.com/arfon/word2vec/master/questions-words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to avoid training, you can download pre-trained models instead in the next section.\n",
    "For training the fastText models yourself, you'll have to follow the setup instructions for [fastText](https://github.com/facebookresearch/fastText) and run the training with -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Progress: 100.0%  words/sec/thread: 31519  lr: 0.000001  loss: 2.289203  eta: 0h0m \n",
      "Train time: 50.000000 sec\n",
      "CPU times: user 1.53 s, sys: 164 ms, total: 1.69 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make sure you set $FT_HOME to your fastText directory root\n",
    "# Training fastText skipgram model on brown corpus\n",
    "!$FT_HOME/fasttext skipgram -input brown_corp.txt -output brown_ft  -lr 0.05 -dim 100 -ws 5 -epoch 5 -minCount 5 -neg 5 -loss ns -t 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 17M words\n",
      "Progress: 100.0%  words/sec/thread: 20536  lr: 0.000001  loss: 1.830005  eta: 0h0m \n",
      "Train time: 1257.000000 sec\n",
      "CPU times: user 29.5 s, sys: 3.75 s, total: 33.3 s\n",
      "Wall time: 21min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training fastText skipgram model on text8 corpus\n",
    "!$FT_HOME/fasttext skipgram -input text8 -output text8_ft -lr 0.05 -dim 100 -ws 5 -epoch 5 -minCount 5 -neg 5 -loss ns -t 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the gensim models -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 17:47:00,842 : INFO : collecting all words and their counts\n",
      "2016-08-08 17:47:00,886 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2016-08-08 17:47:01,704 : INFO : PROGRESS: at sentence #10000, processed 219770 words, keeping 23488 word types\n",
      "2016-08-08 17:47:02,695 : INFO : PROGRESS: at sentence #20000, processed 430477 words, keeping 34367 word types\n",
      "2016-08-08 17:47:03,826 : INFO : PROGRESS: at sentence #30000, processed 669056 words, keeping 42365 word types\n",
      "2016-08-08 17:47:04,638 : INFO : PROGRESS: at sentence #40000, processed 888291 words, keeping 49136 word types\n",
      "2016-08-08 17:47:05,293 : INFO : PROGRESS: at sentence #50000, processed 1039920 words, keeping 53024 word types\n",
      "2016-08-08 17:47:05,781 : INFO : collected 56057 word types from a corpus of 1161192 raw words and 57340 sentences\n",
      "2016-08-08 17:47:05,978 : INFO : min_count=5 retains 15173 unique words (drops 40884)\n",
      "2016-08-08 17:47:05,980 : INFO : min_count leaves 1095086 word corpus (94% of original 1161192)\n",
      "2016-08-08 17:47:06,123 : INFO : deleting the raw counts dictionary of 56057 items\n",
      "2016-08-08 17:47:06,133 : INFO : sample=0.0001 downsamples 340 most-common words\n",
      "2016-08-08 17:47:06,135 : INFO : downsampling leaves estimated 540252 word corpus (49.3% of prior 1095086)\n",
      "2016-08-08 17:47:06,137 : INFO : estimated required memory for 15173 words and 100 dimensions: 19724900 bytes\n",
      "2016-08-08 17:47:06,263 : INFO : resetting layer weights\n",
      "2016-08-08 17:47:06,867 : INFO : training model with 3 workers on 15173 vocabulary and 100 features, using sg=1 hs=0 sample=0.0001 negative=5\n",
      "2016-08-08 17:47:06,869 : INFO : expecting 57340 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-08-08 17:47:07,882 : INFO : PROGRESS: at 1.60% examples, 47954 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:08,933 : INFO : PROGRESS: at 3.22% examples, 45962 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:09,946 : INFO : PROGRESS: at 5.74% examples, 53897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:11,043 : INFO : PROGRESS: at 7.71% examples, 54017 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:12,076 : INFO : PROGRESS: at 9.41% examples, 53809 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:13,086 : INFO : PROGRESS: at 11.38% examples, 55341 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:14,151 : INFO : PROGRESS: at 13.28% examples, 55906 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:15,180 : INFO : PROGRESS: at 15.74% examples, 54815 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:16,201 : INFO : PROGRESS: at 18.25% examples, 54047 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:17,227 : INFO : PROGRESS: at 19.96% examples, 52076 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:18,231 : INFO : PROGRESS: at 21.39% examples, 51280 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:19,254 : INFO : PROGRESS: at 23.61% examples, 52320 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:20,316 : INFO : PROGRESS: at 25.85% examples, 52776 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:21,365 : INFO : PROGRESS: at 27.81% examples, 53065 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:22,375 : INFO : PROGRESS: at 30.30% examples, 54734 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:23,419 : INFO : PROGRESS: at 33.07% examples, 56859 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:24,433 : INFO : PROGRESS: at 37.78% examples, 58908 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:25,441 : INFO : PROGRESS: at 40.88% examples, 59628 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:26,466 : INFO : PROGRESS: at 42.85% examples, 59414 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:27,474 : INFO : PROGRESS: at 44.63% examples, 58979 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:28,482 : INFO : PROGRESS: at 46.87% examples, 59277 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:29,521 : INFO : PROGRESS: at 48.97% examples, 59375 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:30,528 : INFO : PROGRESS: at 51.73% examples, 60729 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:31,549 : INFO : PROGRESS: at 55.35% examples, 61980 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:32,557 : INFO : PROGRESS: at 59.69% examples, 62825 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:33,577 : INFO : PROGRESS: at 63.37% examples, 64465 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:34,577 : INFO : PROGRESS: at 66.06% examples, 64875 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:35,587 : INFO : PROGRESS: at 68.33% examples, 64983 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:36,664 : INFO : PROGRESS: at 70.49% examples, 65023 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:37,716 : INFO : PROGRESS: at 72.53% examples, 65015 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:38,738 : INFO : PROGRESS: at 76.25% examples, 65481 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:39,778 : INFO : PROGRESS: at 80.29% examples, 65984 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:40,806 : INFO : PROGRESS: at 83.20% examples, 66481 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:41,813 : INFO : PROGRESS: at 86.78% examples, 67521 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:42,849 : INFO : PROGRESS: at 89.15% examples, 67604 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:43,867 : INFO : PROGRESS: at 91.36% examples, 67719 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:44,900 : INFO : PROGRESS: at 93.47% examples, 67654 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:45,910 : INFO : PROGRESS: at 96.91% examples, 67604 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-08 17:47:46,509 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-08-08 17:47:46,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-08-08 17:47:46,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-08-08 17:47:46,529 : INFO : training on 5805960 raw words (2701921 effective words) took 39.7s, 68139 effective words/s\n",
      "2016-08-08 17:47:46,538 : INFO : storing 15173x100 projection weights into models/brown_gs.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 332 ms, total: 1min 14s\n",
      "Wall time: 45.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 17:47:47,979 : INFO : collecting all words and their counts\n",
      "2016-08-08 17:47:47,983 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2016-08-08 17:47:59,375 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2016-08-08 17:48:00,240 : INFO : min_count=5 retains 71290 unique words (drops 182564)\n",
      "2016-08-08 17:48:00,241 : INFO : min_count leaves 16718844 word corpus (98% of original 17005207)\n",
      "2016-08-08 17:48:00,682 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2016-08-08 17:48:00,718 : INFO : sample=0.0001 downsamples 341 most-common words\n",
      "2016-08-08 17:48:00,719 : INFO : downsampling leaves estimated 9386181 word corpus (56.1% of prior 16718844)\n",
      "2016-08-08 17:48:00,721 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
      "2016-08-08 17:48:01,104 : INFO : resetting layer weights\n",
      "2016-08-08 17:48:03,003 : INFO : training model with 3 workers on 71290 vocabulary and 100 features, using sg=1 hs=0 sample=0.0001 negative=5\n",
      "2016-08-08 17:48:03,004 : INFO : expecting 1701 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-08-08 17:48:04,051 : INFO : PROGRESS: at 0.34% examples, 155490 words/s, in_qsize 4, out_qsize 2\n",
      "2016-08-08 17:48:05,049 : INFO : PROGRESS: at 0.67% examples, 154562 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:06,130 : INFO : PROGRESS: at 1.02% examples, 153293 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:07,150 : INFO : PROGRESS: at 1.29% examples, 144420 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:08,160 : INFO : PROGRESS: at 1.54% examples, 138213 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:09,170 : INFO : PROGRESS: at 1.82% examples, 136913 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:10,189 : INFO : PROGRESS: at 2.10% examples, 135556 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:11,248 : INFO : PROGRESS: at 2.47% examples, 138986 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:12,275 : INFO : PROGRESS: at 2.86% examples, 143229 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:13,323 : INFO : PROGRESS: at 3.25% examples, 146409 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:14,367 : INFO : PROGRESS: at 3.54% examples, 144935 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:48:15,384 : INFO : PROGRESS: at 3.74% examples, 140590 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:16,421 : INFO : PROGRESS: at 4.01% examples, 139049 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:17,450 : INFO : PROGRESS: at 4.27% examples, 137778 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:18,458 : INFO : PROGRESS: at 4.49% examples, 135570 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:19,477 : INFO : PROGRESS: at 4.83% examples, 137145 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:20,533 : INFO : PROGRESS: at 5.20% examples, 138773 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:48:21,555 : INFO : PROGRESS: at 5.58% examples, 141100 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:22,645 : INFO : PROGRESS: at 5.83% examples, 139212 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:23,708 : INFO : PROGRESS: at 6.10% examples, 138385 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:24,730 : INFO : PROGRESS: at 6.40% examples, 138377 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:25,764 : INFO : PROGRESS: at 6.67% examples, 137806 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:26,793 : INFO : PROGRESS: at 7.03% examples, 139119 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:27,800 : INFO : PROGRESS: at 7.43% examples, 141137 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:28,819 : INFO : PROGRESS: at 7.74% examples, 141051 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:29,845 : INFO : PROGRESS: at 8.01% examples, 140432 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:30,884 : INFO : PROGRESS: at 8.27% examples, 139536 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:31,916 : INFO : PROGRESS: at 8.56% examples, 139433 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:32,921 : INFO : PROGRESS: at 8.83% examples, 138967 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:33,944 : INFO : PROGRESS: at 9.14% examples, 139065 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:34,957 : INFO : PROGRESS: at 9.51% examples, 140208 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:35,991 : INFO : PROGRESS: at 9.86% examples, 140882 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:36,994 : INFO : PROGRESS: at 10.21% examples, 141450 words/s, in_qsize 4, out_qsize 0\n",
      "2016-08-08 17:48:38,034 : INFO : PROGRESS: at 10.55% examples, 141807 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:39,091 : INFO : PROGRESS: at 10.79% examples, 141034 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:40,080 : INFO : PROGRESS: at 11.05% examples, 140529 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:41,089 : INFO : PROGRESS: at 11.35% examples, 140465 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:42,132 : INFO : PROGRESS: at 11.63% examples, 140097 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:43,151 : INFO : PROGRESS: at 12.02% examples, 141100 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:44,162 : INFO : PROGRESS: at 12.39% examples, 141933 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:45,200 : INFO : PROGRESS: at 12.78% examples, 142783 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:46,201 : INFO : PROGRESS: at 13.10% examples, 142895 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:47,232 : INFO : PROGRESS: at 13.35% examples, 142195 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:48,239 : INFO : PROGRESS: at 13.62% examples, 141860 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:49,328 : INFO : PROGRESS: at 13.90% examples, 141405 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:50,356 : INFO : PROGRESS: at 14.12% examples, 140616 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:51,360 : INFO : PROGRESS: at 14.30% examples, 139395 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:52,374 : INFO : PROGRESS: at 14.49% examples, 138279 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:53,433 : INFO : PROGRESS: at 14.67% examples, 137159 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:54,461 : INFO : PROGRESS: at 14.87% examples, 136244 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:55,498 : INFO : PROGRESS: at 15.12% examples, 135536 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:56,500 : INFO : PROGRESS: at 15.36% examples, 134953 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:48:57,554 : INFO : PROGRESS: at 15.60% examples, 134405 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:58,564 : INFO : PROGRESS: at 15.85% examples, 134003 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:48:59,593 : INFO : PROGRESS: at 16.12% examples, 133780 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:00,605 : INFO : PROGRESS: at 16.43% examples, 133919 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:01,630 : INFO : PROGRESS: at 16.68% examples, 133659 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:02,687 : INFO : PROGRESS: at 17.04% examples, 134055 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:03,693 : INFO : PROGRESS: at 17.45% examples, 135020 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:04,696 : INFO : PROGRESS: at 17.79% examples, 135459 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:05,697 : INFO : PROGRESS: at 18.14% examples, 135967 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:06,808 : INFO : PROGRESS: at 18.48% examples, 136057 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:07,808 : INFO : PROGRESS: at 18.75% examples, 135872 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:08,827 : INFO : PROGRESS: at 19.02% examples, 135714 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:09,837 : INFO : PROGRESS: at 19.32% examples, 135718 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:10,856 : INFO : PROGRESS: at 19.68% examples, 136137 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:11,863 : INFO : PROGRESS: at 20.05% examples, 136644 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:12,910 : INFO : PROGRESS: at 20.44% examples, 137228 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:13,970 : INFO : PROGRESS: at 20.81% examples, 137647 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:14,990 : INFO : PROGRESS: at 21.09% examples, 137510 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:16,000 : INFO : PROGRESS: at 21.40% examples, 137472 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:17,051 : INFO : PROGRESS: at 21.66% examples, 137119 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:18,137 : INFO : PROGRESS: at 21.93% examples, 136808 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:19,176 : INFO : PROGRESS: at 22.12% examples, 136089 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:20,176 : INFO : PROGRESS: at 22.32% examples, 135519 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:21,218 : INFO : PROGRESS: at 22.49% examples, 134795 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:22,272 : INFO : PROGRESS: at 22.68% examples, 134132 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:23,332 : INFO : PROGRESS: at 22.92% examples, 133710 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:24,356 : INFO : PROGRESS: at 23.10% examples, 133120 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:49:25,360 : INFO : PROGRESS: at 23.33% examples, 132757 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:26,397 : INFO : PROGRESS: at 23.57% examples, 132503 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:27,443 : INFO : PROGRESS: at 23.87% examples, 132500 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:28,434 : INFO : PROGRESS: at 24.10% examples, 132224 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:29,475 : INFO : PROGRESS: at 24.39% examples, 132195 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:30,488 : INFO : PROGRESS: at 24.63% examples, 132019 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:49:31,488 : INFO : PROGRESS: at 24.86% examples, 131722 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:32,546 : INFO : PROGRESS: at 25.07% examples, 131279 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:33,551 : INFO : PROGRESS: at 25.30% examples, 131059 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:34,625 : INFO : PROGRESS: at 25.55% examples, 130835 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:35,651 : INFO : PROGRESS: at 25.81% examples, 130708 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:36,665 : INFO : PROGRESS: at 26.10% examples, 130796 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:37,688 : INFO : PROGRESS: at 26.35% examples, 130637 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:38,688 : INFO : PROGRESS: at 26.55% examples, 130283 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:39,724 : INFO : PROGRESS: at 26.78% examples, 130043 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:40,855 : INFO : PROGRESS: at 27.00% examples, 129571 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:41,878 : INFO : PROGRESS: at 27.20% examples, 129194 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:49:42,920 : INFO : PROGRESS: at 27.44% examples, 129007 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:43,973 : INFO : PROGRESS: at 27.75% examples, 129071 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:45,014 : INFO : PROGRESS: at 28.02% examples, 129011 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:46,031 : INFO : PROGRESS: at 28.30% examples, 129018 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:47,048 : INFO : PROGRESS: at 28.48% examples, 128570 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:48,085 : INFO : PROGRESS: at 28.67% examples, 128152 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:49,151 : INFO : PROGRESS: at 28.89% examples, 127849 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:50,163 : INFO : PROGRESS: at 29.14% examples, 127738 words/s, in_qsize 4, out_qsize 0\n",
      "2016-08-08 17:49:51,179 : INFO : PROGRESS: at 29.39% examples, 127666 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:52,243 : INFO : PROGRESS: at 29.68% examples, 127635 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:53,284 : INFO : PROGRESS: at 29.92% examples, 127502 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:54,315 : INFO : PROGRESS: at 30.25% examples, 127705 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:55,325 : INFO : PROGRESS: at 30.62% examples, 128116 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:56,342 : INFO : PROGRESS: at 30.97% examples, 128436 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:57,365 : INFO : PROGRESS: at 31.36% examples, 128892 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:49:58,381 : INFO : PROGRESS: at 31.69% examples, 129092 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:49:59,400 : INFO : PROGRESS: at 31.95% examples, 129018 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:00,502 : INFO : PROGRESS: at 32.26% examples, 129094 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:01,501 : INFO : PROGRESS: at 32.53% examples, 129065 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:02,520 : INFO : PROGRESS: at 32.75% examples, 128801 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:50:03,538 : INFO : PROGRESS: at 32.96% examples, 128530 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:04,599 : INFO : PROGRESS: at 33.15% examples, 128138 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:05,663 : INFO : PROGRESS: at 33.31% examples, 127657 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:06,684 : INFO : PROGRESS: at 33.50% examples, 127316 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:07,767 : INFO : PROGRESS: at 33.73% examples, 127109 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:08,785 : INFO : PROGRESS: at 33.94% examples, 126872 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:09,852 : INFO : PROGRESS: at 34.19% examples, 126752 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:10,881 : INFO : PROGRESS: at 34.45% examples, 126657 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:11,908 : INFO : PROGRESS: at 34.71% examples, 126603 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:12,946 : INFO : PROGRESS: at 35.00% examples, 126621 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:50:13,975 : INFO : PROGRESS: at 35.30% examples, 126596 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:14,979 : INFO : PROGRESS: at 35.67% examples, 126912 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:16,017 : INFO : PROGRESS: at 36.05% examples, 127230 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:17,036 : INFO : PROGRESS: at 36.40% examples, 127507 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:18,054 : INFO : PROGRESS: at 36.77% examples, 127811 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:19,061 : INFO : PROGRESS: at 37.04% examples, 127791 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:20,073 : INFO : PROGRESS: at 37.30% examples, 127740 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:21,075 : INFO : PROGRESS: at 37.57% examples, 127726 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:22,133 : INFO : PROGRESS: at 37.82% examples, 127667 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:23,156 : INFO : PROGRESS: at 37.99% examples, 127282 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:24,219 : INFO : PROGRESS: at 38.17% examples, 126907 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:25,280 : INFO : PROGRESS: at 38.37% examples, 126617 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:26,364 : INFO : PROGRESS: at 38.58% examples, 126340 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:27,419 : INFO : PROGRESS: at 38.81% examples, 126176 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:28,450 : INFO : PROGRESS: at 39.01% examples, 125916 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:29,482 : INFO : PROGRESS: at 39.21% examples, 125676 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:50:30,499 : INFO : PROGRESS: at 39.48% examples, 125650 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:31,515 : INFO : PROGRESS: at 39.74% examples, 125589 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:32,519 : INFO : PROGRESS: at 39.98% examples, 125505 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:50:33,527 : INFO : PROGRESS: at 40.27% examples, 125573 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:34,544 : INFO : PROGRESS: at 40.56% examples, 125646 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:35,561 : INFO : PROGRESS: at 40.93% examples, 125906 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:36,600 : INFO : PROGRESS: at 41.34% examples, 126251 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:37,646 : INFO : PROGRESS: at 41.69% examples, 126455 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:38,650 : INFO : PROGRESS: at 41.99% examples, 126515 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:39,714 : INFO : PROGRESS: at 42.28% examples, 126521 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:40,741 : INFO : PROGRESS: at 42.53% examples, 126439 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:50:41,786 : INFO : PROGRESS: at 42.77% examples, 126356 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:42,795 : INFO : PROGRESS: at 43.00% examples, 126202 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:43,818 : INFO : PROGRESS: at 43.16% examples, 125875 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:44,886 : INFO : PROGRESS: at 43.34% examples, 125553 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:45,940 : INFO : PROGRESS: at 43.52% examples, 125249 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:46,973 : INFO : PROGRESS: at 43.74% examples, 125113 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:47,959 : INFO : PROGRESS: at 43.92% examples, 124844 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:48,974 : INFO : PROGRESS: at 44.14% examples, 124713 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:50,167 : INFO : PROGRESS: at 44.27% examples, 124192 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:51,280 : INFO : PROGRESS: at 44.51% examples, 124060 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:52,308 : INFO : PROGRESS: at 44.79% examples, 124085 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:53,333 : INFO : PROGRESS: at 45.06% examples, 124086 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:54,352 : INFO : PROGRESS: at 45.33% examples, 124112 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:55,393 : INFO : PROGRESS: at 45.55% examples, 123975 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:56,459 : INFO : PROGRESS: at 45.76% examples, 123792 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:57,523 : INFO : PROGRESS: at 45.96% examples, 123613 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:50:58,546 : INFO : PROGRESS: at 46.22% examples, 123580 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:50:59,568 : INFO : PROGRESS: at 46.49% examples, 123598 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:00,577 : INFO : PROGRESS: at 46.76% examples, 123625 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:01,635 : INFO : PROGRESS: at 47.02% examples, 123581 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:51:02,661 : INFO : PROGRESS: at 47.23% examples, 123441 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:03,707 : INFO : PROGRESS: at 47.48% examples, 123366 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:04,738 : INFO : PROGRESS: at 47.68% examples, 123178 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:05,801 : INFO : PROGRESS: at 47.88% examples, 122978 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:06,819 : INFO : PROGRESS: at 48.12% examples, 122925 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:07,821 : INFO : PROGRESS: at 48.41% examples, 122985 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:08,837 : INFO : PROGRESS: at 48.67% examples, 122973 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:09,872 : INFO : PROGRESS: at 48.96% examples, 123034 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:10,915 : INFO : PROGRESS: at 49.19% examples, 122937 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:11,959 : INFO : PROGRESS: at 49.39% examples, 122761 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:13,014 : INFO : PROGRESS: at 49.63% examples, 122675 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:14,080 : INFO : PROGRESS: at 49.82% examples, 122445 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:15,115 : INFO : PROGRESS: at 50.06% examples, 122395 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:16,123 : INFO : PROGRESS: at 50.34% examples, 122408 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:17,200 : INFO : PROGRESS: at 50.62% examples, 122434 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:18,231 : INFO : PROGRESS: at 50.86% examples, 122388 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:19,280 : INFO : PROGRESS: at 51.08% examples, 122241 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:20,283 : INFO : PROGRESS: at 51.26% examples, 122074 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:21,287 : INFO : PROGRESS: at 51.43% examples, 121843 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:22,339 : INFO : PROGRESS: at 51.64% examples, 121698 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:23,350 : INFO : PROGRESS: at 51.90% examples, 121696 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:24,367 : INFO : PROGRESS: at 52.18% examples, 121746 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:25,415 : INFO : PROGRESS: at 52.44% examples, 121722 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:51:26,420 : INFO : PROGRESS: at 52.72% examples, 121771 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:27,435 : INFO : PROGRESS: at 53.10% examples, 122020 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:28,446 : INFO : PROGRESS: at 53.45% examples, 122234 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:29,484 : INFO : PROGRESS: at 53.79% examples, 122399 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:30,553 : INFO : PROGRESS: at 54.16% examples, 122599 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:31,581 : INFO : PROGRESS: at 54.42% examples, 122582 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:32,591 : INFO : PROGRESS: at 54.67% examples, 122571 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:33,615 : INFO : PROGRESS: at 54.98% examples, 122645 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:34,640 : INFO : PROGRESS: at 55.20% examples, 122494 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:35,641 : INFO : PROGRESS: at 55.38% examples, 122284 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:36,649 : INFO : PROGRESS: at 55.54% examples, 122056 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:51:37,656 : INFO : PROGRESS: at 55.74% examples, 121912 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:38,695 : INFO : PROGRESS: at 55.93% examples, 121727 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:39,699 : INFO : PROGRESS: at 56.17% examples, 121671 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:40,718 : INFO : PROGRESS: at 56.36% examples, 121506 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:41,770 : INFO : PROGRESS: at 56.55% examples, 121346 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:42,799 : INFO : PROGRESS: at 56.79% examples, 121299 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:51:43,819 : INFO : PROGRESS: at 57.07% examples, 121324 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:44,821 : INFO : PROGRESS: at 57.33% examples, 121329 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:45,828 : INFO : PROGRESS: at 57.59% examples, 121322 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:46,845 : INFO : PROGRESS: at 57.79% examples, 121209 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:47,843 : INFO : PROGRESS: at 57.95% examples, 121014 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:48,890 : INFO : PROGRESS: at 58.18% examples, 120917 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:49,903 : INFO : PROGRESS: at 58.37% examples, 120756 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:51:50,915 : INFO : PROGRESS: at 58.61% examples, 120727 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:52,005 : INFO : PROGRESS: at 58.92% examples, 120768 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:53,048 : INFO : PROGRESS: at 59.17% examples, 120730 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:54,052 : INFO : PROGRESS: at 59.44% examples, 120738 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:55,084 : INFO : PROGRESS: at 59.68% examples, 120698 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:56,111 : INFO : PROGRESS: at 59.89% examples, 120590 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:57,123 : INFO : PROGRESS: at 60.12% examples, 120517 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:51:58,188 : INFO : PROGRESS: at 60.33% examples, 120403 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:51:59,218 : INFO : PROGRESS: at 60.59% examples, 120390 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:00,324 : INFO : PROGRESS: at 60.89% examples, 120419 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:01,352 : INFO : PROGRESS: at 61.19% examples, 120467 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:02,384 : INFO : PROGRESS: at 61.47% examples, 120472 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:03,424 : INFO : PROGRESS: at 61.88% examples, 120745 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:04,440 : INFO : PROGRESS: at 62.25% examples, 120933 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:05,471 : INFO : PROGRESS: at 62.60% examples, 121103 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:52:06,487 : INFO : PROGRESS: at 62.96% examples, 121302 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:07,488 : INFO : PROGRESS: at 63.23% examples, 121326 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:08,499 : INFO : PROGRESS: at 63.49% examples, 121318 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:09,506 : INFO : PROGRESS: at 63.77% examples, 121356 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:10,506 : INFO : PROGRESS: at 64.02% examples, 121332 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:11,538 : INFO : PROGRESS: at 64.19% examples, 121141 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:12,613 : INFO : PROGRESS: at 64.36% examples, 120954 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:13,668 : INFO : PROGRESS: at 64.57% examples, 120844 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:14,704 : INFO : PROGRESS: at 64.74% examples, 120667 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:15,711 : INFO : PROGRESS: at 64.95% examples, 120579 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:16,778 : INFO : PROGRESS: at 65.19% examples, 120519 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:17,922 : INFO : PROGRESS: at 65.40% examples, 120372 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:18,989 : INFO : PROGRESS: at 65.67% examples, 120371 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:20,016 : INFO : PROGRESS: at 65.95% examples, 120425 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:21,037 : INFO : PROGRESS: at 66.21% examples, 120424 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:22,054 : INFO : PROGRESS: at 66.48% examples, 120453 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:23,189 : INFO : PROGRESS: at 66.71% examples, 120360 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:24,222 : INFO : PROGRESS: at 66.94% examples, 120293 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:25,279 : INFO : PROGRESS: at 67.16% examples, 120213 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:52:26,346 : INFO : PROGRESS: at 67.40% examples, 120150 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:27,360 : INFO : PROGRESS: at 67.67% examples, 120161 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:28,423 : INFO : PROGRESS: at 67.94% examples, 120167 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:29,467 : INFO : PROGRESS: at 68.21% examples, 120165 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:30,540 : INFO : PROGRESS: at 68.49% examples, 120193 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:52:31,590 : INFO : PROGRESS: at 68.71% examples, 120107 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:32,669 : INFO : PROGRESS: at 68.92% examples, 120005 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:33,743 : INFO : PROGRESS: at 69.17% examples, 119964 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:34,718 : INFO : PROGRESS: at 69.41% examples, 119930 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:35,720 : INFO : PROGRESS: at 69.65% examples, 119916 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:36,761 : INFO : PROGRESS: at 69.95% examples, 119976 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:37,760 : INFO : PROGRESS: at 70.21% examples, 119977 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:38,770 : INFO : PROGRESS: at 70.42% examples, 119893 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:39,870 : INFO : PROGRESS: at 70.66% examples, 119853 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:40,935 : INFO : PROGRESS: at 70.88% examples, 119759 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:41,963 : INFO : PROGRESS: at 71.09% examples, 119680 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:42,967 : INFO : PROGRESS: at 71.30% examples, 119605 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:52:44,000 : INFO : PROGRESS: at 71.60% examples, 119672 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:45,014 : INFO : PROGRESS: at 71.88% examples, 119695 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:46,060 : INFO : PROGRESS: at 72.17% examples, 119742 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:47,108 : INFO : PROGRESS: at 72.38% examples, 119648 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:48,125 : INFO : PROGRESS: at 72.60% examples, 119598 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:49,141 : INFO : PROGRESS: at 72.84% examples, 119553 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:50,154 : INFO : PROGRESS: at 73.04% examples, 119457 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:51,159 : INFO : PROGRESS: at 73.31% examples, 119481 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:52,191 : INFO : PROGRESS: at 73.59% examples, 119517 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:53,197 : INFO : PROGRESS: at 73.84% examples, 119507 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:54,222 : INFO : PROGRESS: at 74.11% examples, 119524 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:52:55,258 : INFO : PROGRESS: at 74.34% examples, 119475 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:52:56,274 : INFO : PROGRESS: at 74.53% examples, 119366 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:57,293 : INFO : PROGRESS: at 74.73% examples, 119276 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:58,322 : INFO : PROGRESS: at 74.96% examples, 119208 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:52:59,369 : INFO : PROGRESS: at 75.26% examples, 119230 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:00,383 : INFO : PROGRESS: at 75.54% examples, 119243 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:01,386 : INFO : PROGRESS: at 75.83% examples, 119277 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:02,392 : INFO : PROGRESS: at 76.05% examples, 119223 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:03,421 : INFO : PROGRESS: at 76.25% examples, 119127 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:04,443 : INFO : PROGRESS: at 76.47% examples, 119071 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:05,466 : INFO : PROGRESS: at 76.66% examples, 118961 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:06,506 : INFO : PROGRESS: at 76.88% examples, 118902 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:53:07,555 : INFO : PROGRESS: at 77.14% examples, 118890 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:08,599 : INFO : PROGRESS: at 77.40% examples, 118880 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:09,603 : INFO : PROGRESS: at 77.68% examples, 118929 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:10,618 : INFO : PROGRESS: at 77.90% examples, 118863 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:11,626 : INFO : PROGRESS: at 78.07% examples, 118750 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:12,661 : INFO : PROGRESS: at 78.31% examples, 118706 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:13,740 : INFO : PROGRESS: at 78.51% examples, 118588 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:14,818 : INFO : PROGRESS: at 78.77% examples, 118557 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:15,908 : INFO : PROGRESS: at 79.05% examples, 118570 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:16,956 : INFO : PROGRESS: at 79.35% examples, 118630 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:17,958 : INFO : PROGRESS: at 79.62% examples, 118645 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:18,988 : INFO : PROGRESS: at 79.85% examples, 118590 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:20,114 : INFO : PROGRESS: at 80.09% examples, 118537 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:21,193 : INFO : PROGRESS: at 80.33% examples, 118489 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:22,230 : INFO : PROGRESS: at 80.56% examples, 118453 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:23,267 : INFO : PROGRESS: at 80.83% examples, 118454 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:24,327 : INFO : PROGRESS: at 81.13% examples, 118481 words/s, in_qsize 6, out_qsize 1\n",
      "2016-08-08 17:53:25,372 : INFO : PROGRESS: at 81.43% examples, 118519 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:26,406 : INFO : PROGRESS: at 81.69% examples, 118512 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:27,447 : INFO : PROGRESS: at 81.93% examples, 118471 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:53:28,518 : INFO : PROGRESS: at 82.16% examples, 118415 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:29,555 : INFO : PROGRESS: at 82.38% examples, 118338 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:30,589 : INFO : PROGRESS: at 82.63% examples, 118335 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:31,619 : INFO : PROGRESS: at 82.89% examples, 118337 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:32,625 : INFO : PROGRESS: at 83.16% examples, 118359 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:33,644 : INFO : PROGRESS: at 83.47% examples, 118430 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:34,687 : INFO : PROGRESS: at 83.70% examples, 118389 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:35,711 : INFO : PROGRESS: at 83.92% examples, 118317 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:36,737 : INFO : PROGRESS: at 84.15% examples, 118285 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:37,760 : INFO : PROGRESS: at 84.36% examples, 118224 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:38,793 : INFO : PROGRESS: at 84.59% examples, 118175 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:39,830 : INFO : PROGRESS: at 84.88% examples, 118232 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:40,832 : INFO : PROGRESS: at 85.13% examples, 118229 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:41,862 : INFO : PROGRESS: at 85.40% examples, 118250 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:42,909 : INFO : PROGRESS: at 85.66% examples, 118252 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:43,950 : INFO : PROGRESS: at 85.87% examples, 118183 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:44,994 : INFO : PROGRESS: at 86.08% examples, 118125 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:46,106 : INFO : PROGRESS: at 86.33% examples, 118086 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:47,111 : INFO : PROGRESS: at 86.57% examples, 118086 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:48,135 : INFO : PROGRESS: at 86.84% examples, 118111 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:49,144 : INFO : PROGRESS: at 87.13% examples, 118157 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:50,152 : INFO : PROGRESS: at 87.38% examples, 118163 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:51,202 : INFO : PROGRESS: at 87.62% examples, 118126 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:52,318 : INFO : PROGRESS: at 87.84% examples, 118043 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:53,334 : INFO : PROGRESS: at 88.04% examples, 117971 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:54,351 : INFO : PROGRESS: at 88.28% examples, 117942 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:55,393 : INFO : PROGRESS: at 88.55% examples, 117965 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:53:56,417 : INFO : PROGRESS: at 88.82% examples, 117976 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:57,441 : INFO : PROGRESS: at 89.10% examples, 118014 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:58,470 : INFO : PROGRESS: at 89.36% examples, 118016 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:53:59,483 : INFO : PROGRESS: at 89.56% examples, 117943 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:00,519 : INFO : PROGRESS: at 89.78% examples, 117897 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:01,536 : INFO : PROGRESS: at 89.99% examples, 117846 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:02,555 : INFO : PROGRESS: at 90.22% examples, 117805 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:03,600 : INFO : PROGRESS: at 90.49% examples, 117811 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:04,679 : INFO : PROGRESS: at 90.79% examples, 117871 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:05,686 : INFO : PROGRESS: at 91.05% examples, 117880 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:06,714 : INFO : PROGRESS: at 91.32% examples, 117899 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:07,721 : INFO : PROGRESS: at 91.52% examples, 117828 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:08,741 : INFO : PROGRESS: at 91.73% examples, 117772 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:09,741 : INFO : PROGRESS: at 91.93% examples, 117711 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:10,807 : INFO : PROGRESS: at 92.20% examples, 117717 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:54:11,884 : INFO : PROGRESS: at 92.48% examples, 117721 words/s, in_qsize 5, out_qsize 2\n",
      "2016-08-08 17:54:12,936 : INFO : PROGRESS: at 92.78% examples, 117773 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:13,938 : INFO : PROGRESS: at 93.03% examples, 117763 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:14,984 : INFO : PROGRESS: at 93.26% examples, 117730 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:16,037 : INFO : PROGRESS: at 93.46% examples, 117650 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:17,087 : INFO : PROGRESS: at 93.71% examples, 117635 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:18,133 : INFO : PROGRESS: at 93.91% examples, 117558 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:19,175 : INFO : PROGRESS: at 94.17% examples, 117559 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:54:20,206 : INFO : PROGRESS: at 94.46% examples, 117608 words/s, in_qsize 5, out_qsize 1\n",
      "2016-08-08 17:54:21,223 : INFO : PROGRESS: at 94.74% examples, 117641 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:22,225 : INFO : PROGRESS: at 95.03% examples, 117663 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:23,242 : INFO : PROGRESS: at 95.25% examples, 117603 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:24,263 : INFO : PROGRESS: at 95.50% examples, 117574 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:25,317 : INFO : PROGRESS: at 95.72% examples, 117525 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:26,324 : INFO : PROGRESS: at 95.93% examples, 117466 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:27,326 : INFO : PROGRESS: at 96.20% examples, 117488 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:28,339 : INFO : PROGRESS: at 96.47% examples, 117508 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:29,377 : INFO : PROGRESS: at 96.73% examples, 117509 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:30,448 : INFO : PROGRESS: at 97.01% examples, 117524 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:31,458 : INFO : PROGRESS: at 97.24% examples, 117488 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:32,490 : INFO : PROGRESS: at 97.43% examples, 117409 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:33,514 : INFO : PROGRESS: at 97.64% examples, 117353 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:34,528 : INFO : PROGRESS: at 97.86% examples, 117324 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:35,559 : INFO : PROGRESS: at 98.12% examples, 117328 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:36,601 : INFO : PROGRESS: at 98.42% examples, 117373 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:37,628 : INFO : PROGRESS: at 98.69% examples, 117387 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:38,712 : INFO : PROGRESS: at 98.94% examples, 117354 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:39,747 : INFO : PROGRESS: at 99.19% examples, 117344 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:40,759 : INFO : PROGRESS: at 99.40% examples, 117286 words/s, in_qsize 6, out_qsize 0\n",
      "2016-08-08 17:54:41,832 : INFO : PROGRESS: at 99.61% examples, 117220 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:42,841 : INFO : PROGRESS: at 99.84% examples, 117185 words/s, in_qsize 5, out_qsize 0\n",
      "2016-08-08 17:54:43,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-08-08 17:54:43,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-08-08 17:54:43,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-08-08 17:54:43,389 : INFO : training on 85026035 raw words (46929778 effective words) took 400.4s, 117213 effective words/s\n",
      "2016-08-08 17:54:43,391 : INFO : storing 71290x100 projection weights into models/text8_gs.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 52s, sys: 2.36 s, total: 18min 54s\n",
      "Wall time: 6min 55s\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "import logging\n",
    "logging.root.handlers = []\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "# Make sure you create a models dir in case it doesn't exist, or modify MODELS_DIR\n",
    "MODELS_DIR = 'models/'\n",
    "\n",
    "# Same values as used for fastText training above\n",
    "params = {\n",
    "    'alpha': 0.05,\n",
    "    'size': 100,\n",
    "    'window': 5,\n",
    "    'iter': 5,\n",
    "    'min_count': 5,\n",
    "    'sample': 1e-4,\n",
    "    'sg': 1,\n",
    "    'hs': 0,\n",
    "    'negative': 5\n",
    "}\n",
    "\n",
    "%time brown_gs = Word2Vec(brown.sents(), **params)\n",
    "brown_gs.save_word2vec_format(MODELS_DIR + 'brown_gs.vec')\n",
    "\n",
    "%time text8_gs = Word2Vec(Text8Corpus('text8'), **params)\n",
    "text8_gs.save_word2vec_format(MODELS_DIR + 'text8_gs.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download models\n",
    "In case you wish to avoid downloading the corpus and training the models, you can download pretrained models with - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download the fastText and gensim models trained on the brown corpus and text8 corpus\n",
    "!wget https://www.dropbox.com/s/d15f3eumu3i8ld6/models.tar.gz?dl=1 -O models.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have downloaded or trained the models (make sure they're in the `models/` directory, or that you've appropriately changed `MODELS_DIR`) and downloaded `questions-words.txt`, you're ready to run the comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:12:42,844 : INFO : loading projection weights from models/brown_ft.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading FastText embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:12:44,951 : INFO : loaded (15173, 100) matrix from models/brown_ft.vec\n",
      "2016-08-08 18:12:45,075 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FastText:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:12:46,081 : INFO : family: 14.8% (27/182)\n",
      "2016-08-08 18:12:50,798 : INFO : gram1-adjective-to-adverb: 73.5% (516/702)\n",
      "2016-08-08 18:12:51,852 : INFO : gram2-opposite: 81.8% (108/132)\n",
      "2016-08-08 18:12:59,736 : INFO : gram3-comparative: 61.5% (649/1056)\n",
      "2016-08-08 18:13:01,312 : INFO : gram4-superlative: 68.6% (144/210)\n",
      "2016-08-08 18:13:04,920 : INFO : gram5-present-participle: 67.1% (436/650)\n",
      "2016-08-08 18:13:19,036 : INFO : gram7-past-tense: 11.5% (145/1260)\n",
      "2016-08-08 18:13:25,371 : INFO : gram8-plural: 60.5% (334/552)\n",
      "2016-08-08 18:13:28,636 : INFO : gram9-plural-verbs: 71.1% (243/342)\n",
      "2016-08-08 18:13:28,643 : INFO : total: 51.2% (2602/5086)\n",
      "2016-08-08 18:13:28,655 : INFO : loading projection weights from models/brown_gs.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 27/182, Accuracy: 14.84%\n",
      "Syntactic: 2575/4904, Accuracy: 52.51%\n",
      "\n",
      "\n",
      "Loading Gensim embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:13:34,891 : INFO : loaded (15173, 100) matrix from models/brown_gs.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Word2Vec:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:13:35,170 : INFO : precomputing L2-norms of word weight vectors\n",
      "2016-08-08 18:13:36,717 : INFO : family: 24.2% (44/182)\n",
      "2016-08-08 18:13:43,872 : INFO : gram1-adjective-to-adverb: 0.6% (4/702)\n",
      "2016-08-08 18:13:45,106 : INFO : gram2-opposite: 0.8% (1/132)\n",
      "2016-08-08 18:13:56,865 : INFO : gram3-comparative: 3.4% (36/1056)\n",
      "2016-08-08 18:13:59,292 : INFO : gram4-superlative: 1.4% (3/210)\n",
      "2016-08-08 18:14:06,379 : INFO : gram5-present-participle: 0.8% (5/650)\n",
      "2016-08-08 18:14:18,778 : INFO : gram7-past-tense: 1.4% (18/1260)\n",
      "2016-08-08 18:14:22,712 : INFO : gram8-plural: 4.9% (27/552)\n",
      "2016-08-08 18:14:25,127 : INFO : gram9-plural-verbs: 1.5% (5/342)\n",
      "2016-08-08 18:14:25,130 : INFO : total: 2.8% (143/5086)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 44/182, Accuracy: 24.18%\n",
      "Syntactic: 99/4904, Accuracy: 2.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def print_accuracy(model, questions_file):\n",
    "    print('Evaluating...\\n')\n",
    "    acc = model.accuracy(questions_file)\n",
    "\n",
    "    sem_correct = sum((len(acc[i]['correct']) for i in range(5)))\n",
    "    sem_total = sum((len(acc[i]['correct']) + len(acc[i]['incorrect'])) for i in range(5))\n",
    "    print('\\nSemantic: {:d}/{:d}, Accuracy: {:.2f}%'.format(sem_correct, sem_total, 100*float(sem_correct)/sem_total))\n",
    "    \n",
    "    syn_correct = sum((len(acc[i]['correct']) for i in range(5, len(acc)-1)))\n",
    "    syn_total = sum((len(acc[i]['correct']) + len(acc[i]['incorrect'])) for i in range(5,len(acc)-1))\n",
    "    print('Syntactic: {:d}/{:d}, Accuracy: {:.2f}%\\n'.format(syn_correct, syn_total, 100*float(syn_correct)/syn_total))\n",
    "\n",
    "MODELS_DIR = 'models/'\n",
    "\n",
    "word_analogies_file = 'questions-words.txt'\n",
    "print('\\nLoading FastText embeddings')\n",
    "brown_ft = Word2Vec.load_word2vec_format(MODELS_DIR + 'brown_ft.vec')\n",
    "print('Accuracy for FastText:')\n",
    "print_accuracy(brown_ft, word_analogies_file)\n",
    "\n",
    "print('\\nLoading Gensim embeddings')\n",
    "brown_gs = Word2Vec.load_word2vec_format(MODELS_DIR + 'brown_gs.vec')\n",
    "print('Accuracy for Word2Vec:')\n",
    "print_accuracy(brown_gs, word_analogies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec embeddings seem to be slightly better than fastText embeddings at the semantic tasks, while the fastText embeddings do significantly better on the syntactic analogies. Makes sense, since fastText embeddings are trained for understanding morphological nuances, and most of the syntactic analogies are morphology based. \n",
    "\n",
    "Let me explain that better.\n",
    "\n",
    "According to the paper [[1]](https://arxiv.org/abs/1607.04606), embeddings for words are represented by the sum of their n-gram embeddings. This is meant to be useful for morphologically rich languages - so theoretically, the embedding for `apparently` would include information from both character n-grams `apparent` and `ly` (as well as other n-grams), and the n-grams would combine in a simple, linear manner. This is very similar to what most of our syntactic tasks look like.\n",
    "\n",
    "Example analogy:\n",
    "\n",
    "`amazing amazingly calm calmly`\n",
    "\n",
    "This analogy is marked correct if: \n",
    "\n",
    "`embedding(amazing)` - `embedding(amazingly)` = `embedding(calm)` - `embedding(calmly)`\n",
    "\n",
    "Both these subtractions would result in a very similar set of remaining ngrams.\n",
    "No surprise the fastText embeddings do extremely well on this.\n",
    "\n",
    "Let's do a small test to validate this hypothesis - fastText differs from word2vec only in that it uses char n-gram embeddings as well as the actual word embedding in the scoring function to calculate scores and then likelihoods for each word, given a context word. In case char n-gram embeddings are not present, this reduces (atleast theoretically) to the original word2vec model. This can be implemented by setting 0 for the max length of char n-grams for fastText.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Progress: 100.0%  words/sec/thread: 55755  lr: 0.000001  loss: 2.356848  eta: 0h0m \n",
      "Train time: 31.000000 sec\n",
      "CPU times: user 1.32 s, sys: 240 ms, total: 1.56 s\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training fastText skipgram model on brown corpus without n-grams\n",
    "# If you chose to download the models, this model will already be present in the MODELS_DIR directory\n",
    "!$FT_HOME/fasttext skipgram -input brown_corp.txt -output brown_ft_no_ng -lr 0.05 -dim 100 -ws 5 -epoch 5 -minCount 5 -neg 5 -loss ns -t 0.0001 -maxn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 17M words\n",
      "Progress: 100.0%  words/sec/thread: 49050  lr: 0.000001  loss: 1.879224  eta: 0h0m \n",
      "Train time: 514.000000 sec\n",
      "CPU times: user 13.2 s, sys: 1.89 s, total: 15.1 s\n",
      "Wall time: 9min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training fastText skipgram model on text8 corpus without n-grams\n",
    "# If you chose to download the models, this model will already be present in the MODELS_DIR directory\n",
    "!$FT_HOME/fasttext skipgram -input text8 -output text8_ft_no_ng -lr 0.05 -dim 100 -ws 5 -epoch 5 -minCount 5 -neg 5 -loss ns -t 0.0001 -maxn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:14:40,553 : INFO : loading projection weights from models/brown_ft_no_ng.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:14:42,619 : INFO : loaded (15173, 100) matrix from models/brown_ft_no_ng.vec\n",
      "2016-08-08 18:14:42,881 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FastText (without n-grams):\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:14:44,144 : INFO : family: 17.6% (32/182)\n",
      "2016-08-08 18:14:49,098 : INFO : gram1-adjective-to-adverb: 0.1% (1/702)\n",
      "2016-08-08 18:14:50,116 : INFO : gram2-opposite: 0.0% (0/132)\n",
      "2016-08-08 18:14:55,390 : INFO : gram3-comparative: 2.8% (30/1056)\n",
      "2016-08-08 18:14:57,268 : INFO : gram4-superlative: 0.5% (1/210)\n",
      "2016-08-08 18:15:02,244 : INFO : gram5-present-participle: 1.4% (9/650)\n",
      "2016-08-08 18:15:11,160 : INFO : gram7-past-tense: 1.0% (12/1260)\n",
      "2016-08-08 18:15:13,591 : INFO : gram8-plural: 6.3% (35/552)\n",
      "2016-08-08 18:15:16,559 : INFO : gram9-plural-verbs: 1.2% (4/342)\n",
      "2016-08-08 18:15:16,562 : INFO : total: 2.4% (124/5086)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 32/182, Accuracy: 17.58%\n",
      "Syntactic: 92/4904, Accuracy: 1.88%\n",
      "\n",
      "Accuracy for Word2Vec:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:15:17,910 : INFO : family: 24.2% (44/182)\n",
      "2016-08-08 18:15:25,713 : INFO : gram1-adjective-to-adverb: 0.6% (4/702)\n",
      "2016-08-08 18:15:26,494 : INFO : gram2-opposite: 0.8% (1/132)\n",
      "2016-08-08 18:15:33,222 : INFO : gram3-comparative: 3.4% (36/1056)\n",
      "2016-08-08 18:15:34,613 : INFO : gram4-superlative: 1.4% (3/210)\n",
      "2016-08-08 18:15:40,954 : INFO : gram5-present-participle: 0.8% (5/650)\n",
      "2016-08-08 18:15:54,275 : INFO : gram7-past-tense: 1.4% (18/1260)\n",
      "2016-08-08 18:15:58,115 : INFO : gram8-plural: 4.9% (27/552)\n",
      "2016-08-08 18:15:59,760 : INFO : gram9-plural-verbs: 1.5% (5/342)\n",
      "2016-08-08 18:15:59,762 : INFO : total: 2.8% (143/5086)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 44/182, Accuracy: 24.18%\n",
      "Syntactic: 99/4904, Accuracy: 2.02%\n",
      "\n",
      "Accuracy for FastText (with n-grams):\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:16:00,606 : INFO : family: 14.8% (27/182)\n",
      "2016-08-08 18:16:05,544 : INFO : gram1-adjective-to-adverb: 73.5% (516/702)\n",
      "2016-08-08 18:16:06,491 : INFO : gram2-opposite: 81.8% (108/132)\n",
      "2016-08-08 18:16:13,179 : INFO : gram3-comparative: 61.5% (649/1056)\n",
      "2016-08-08 18:16:14,931 : INFO : gram4-superlative: 68.6% (144/210)\n",
      "2016-08-08 18:16:19,684 : INFO : gram5-present-participle: 67.1% (436/650)\n",
      "2016-08-08 18:16:29,727 : INFO : gram7-past-tense: 11.5% (145/1260)\n",
      "2016-08-08 18:16:33,346 : INFO : gram8-plural: 60.5% (334/552)\n",
      "2016-08-08 18:16:37,013 : INFO : gram9-plural-verbs: 71.1% (243/342)\n",
      "2016-08-08 18:16:37,017 : INFO : total: 51.2% (2602/5086)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 27/182, Accuracy: 14.84%\n",
      "Syntactic: 2575/4904, Accuracy: 52.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading FastText embeddings')\n",
    "brown_ft_no_ng = Word2Vec.load_word2vec_format(MODELS_DIR + 'brown_ft_no_ng.vec')\n",
    "print('Accuracy for FastText (without n-grams):')\n",
    "print_accuracy(brown_ft_no_ng, word_analogies_file)\n",
    "\n",
    "print('Accuracy for Word2Vec:')\n",
    "print_accuracy(brown_gs, word_analogies_file)\n",
    "\n",
    "print('Accuracy for FastText (with n-grams):')\n",
    "print_accuracy(brown_ft, word_analogies_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-ha! The results for FastText with no n-grams and Word2Vec look a lot more similar (as they should) - the differences could easily result from differences in implementation between fastText and Gensim, and randomization. Especially telling is that the semantic accuracy for FastText has more or less remained the same after removing n-grams, while the syntactic accuracy has taken a giant dive. Our hypothesis that the char n-grams result in better performance on syntactic analogies seems fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a larger corpus now - text8 (collection of wiki articles). I'm also curious about the impact on semantic accuracy - for models trained on the brown corpus, the difference in the semantic accuracy and the accuracy values themselves are too small to be conclusive. Hopefully a larger corpus helps, and the text8 corpus likely has a lot more information about capitals, currencies, cities etc, which should be relevant to the semantic tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:16:44,115 : INFO : loading projection weights from models/text8_ft_no_ng.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:16:58,690 : INFO : loaded (71290, 100) matrix from models/text8_ft_no_ng.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FastText (without n-grams):\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:16:59,241 : INFO : precomputing L2-norms of word weight vectors\n",
      "2016-08-08 18:17:08,464 : INFO : capital-common-countries: 71.5% (362/506)\n",
      "2016-08-08 18:17:27,746 : INFO : capital-world: 48.6% (706/1452)\n",
      "2016-08-08 18:17:31,516 : INFO : currency: 22.0% (59/268)\n",
      "2016-08-08 18:17:54,621 : INFO : city-in-state: 23.7% (358/1511)\n",
      "2016-08-08 18:17:59,452 : INFO : family: 63.7% (195/306)\n",
      "2016-08-08 18:18:09,547 : INFO : gram1-adjective-to-adverb: 14.4% (109/756)\n",
      "2016-08-08 18:18:14,506 : INFO : gram2-opposite: 14.4% (44/306)\n",
      "2016-08-08 18:18:33,499 : INFO : gram3-comparative: 41.7% (526/1260)\n",
      "2016-08-08 18:18:39,790 : INFO : gram4-superlative: 27.7% (140/506)\n",
      "2016-08-08 18:18:55,154 : INFO : gram5-present-participle: 24.0% (238/992)\n",
      "2016-08-08 18:19:15,897 : INFO : gram6-nationality-adjective: 78.8% (1080/1371)\n",
      "2016-08-08 18:19:38,978 : INFO : gram7-past-tense: 35.1% (467/1332)\n",
      "2016-08-08 18:19:53,881 : INFO : gram8-plural: 52.9% (525/992)\n",
      "2016-08-08 18:20:02,998 : INFO : gram9-plural-verbs: 26.5% (172/650)\n",
      "2016-08-08 18:20:03,004 : INFO : total: 40.8% (4981/12208)\n",
      "2016-08-08 18:20:03,017 : INFO : loading projection weights from models/text8_gs.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 1680/4043, Accuracy: 41.55%\n",
      "Syntactic: 3301/8165, Accuracy: 40.43%\n",
      "\n",
      "Loading Gensim embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:20:18,229 : INFO : loaded (71290, 100) matrix from models/text8_gs.vec\n",
      "2016-08-08 18:20:18,482 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for word2vec:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:20:23,125 : INFO : capital-common-countries: 67.2% (340/506)\n",
      "2016-08-08 18:20:45,232 : INFO : capital-world: 45.5% (661/1452)\n",
      "2016-08-08 18:20:50,051 : INFO : currency: 22.4% (60/268)\n",
      "2016-08-08 18:21:09,436 : INFO : city-in-state: 23.0% (361/1571)\n",
      "2016-08-08 18:21:14,049 : INFO : family: 57.8% (177/306)\n",
      "2016-08-08 18:21:25,828 : INFO : gram1-adjective-to-adverb: 16.4% (124/756)\n",
      "2016-08-08 18:21:30,659 : INFO : gram2-opposite: 10.8% (33/306)\n",
      "2016-08-08 18:21:48,540 : INFO : gram3-comparative: 53.1% (669/1260)\n",
      "2016-08-08 18:21:55,544 : INFO : gram4-superlative: 30.8% (156/506)\n",
      "2016-08-08 18:22:09,282 : INFO : gram5-present-participle: 25.3% (251/992)\n",
      "2016-08-08 18:22:25,471 : INFO : gram6-nationality-adjective: 77.5% (1063/1371)\n",
      "2016-08-08 18:22:45,242 : INFO : gram7-past-tense: 32.0% (426/1332)\n",
      "2016-08-08 18:23:03,272 : INFO : gram8-plural: 51.1% (507/992)\n",
      "2016-08-08 18:23:11,655 : INFO : gram9-plural-verbs: 27.4% (178/650)\n",
      "2016-08-08 18:23:11,660 : INFO : total: 40.8% (5006/12268)\n",
      "2016-08-08 18:23:11,682 : INFO : loading projection weights from models/text8_ft.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 1599/4103, Accuracy: 38.97%\n",
      "Syntactic: 3407/8165, Accuracy: 41.73%\n",
      "\n",
      "Loading FastText embeddings (with n-grams)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:23:25,010 : INFO : loaded (71290, 100) matrix from models/text8_ft.vec\n",
      "2016-08-08 18:23:25,208 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FastText (with n-grams):\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-08 18:23:34,556 : INFO : capital-common-countries: 57.5% (291/506)\n",
      "2016-08-08 18:24:00,347 : INFO : capital-world: 42.2% (613/1452)\n",
      "2016-08-08 18:24:04,067 : INFO : currency: 11.9% (32/268)\n",
      "2016-08-08 18:24:30,388 : INFO : city-in-state: 18.3% (277/1511)\n",
      "2016-08-08 18:24:36,499 : INFO : family: 51.6% (158/306)\n",
      "2016-08-08 18:24:48,265 : INFO : gram1-adjective-to-adverb: 74.5% (563/756)\n",
      "2016-08-08 18:24:53,082 : INFO : gram2-opposite: 59.8% (183/306)\n",
      "2016-08-08 18:25:13,457 : INFO : gram3-comparative: 68.7% (865/1260)\n",
      "2016-08-08 18:25:20,501 : INFO : gram4-superlative: 53.2% (269/506)\n",
      "2016-08-08 18:25:35,751 : INFO : gram5-present-participle: 57.1% (566/992)\n",
      "2016-08-08 18:25:58,592 : INFO : gram6-nationality-adjective: 94.7% (1299/1371)\n",
      "2016-08-08 18:26:16,917 : INFO : gram7-past-tense: 36.6% (487/1332)\n",
      "2016-08-08 18:26:30,900 : INFO : gram8-plural: 91.3% (906/992)\n",
      "2016-08-08 18:26:41,516 : INFO : gram9-plural-verbs: 56.6% (368/650)\n",
      "2016-08-08 18:26:41,520 : INFO : total: 56.3% (6877/12208)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic: 1371/4043, Accuracy: 33.91%\n",
      "Syntactic: 5506/8165, Accuracy: 67.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading FastText embeddings')\n",
    "text8_ft_no_ng = Word2Vec.load_word2vec_format(MODELS_DIR + 'text8_ft_no_ng.vec')\n",
    "print('Accuracy for FastText (without n-grams):')\n",
    "print_accuracy(text8_ft_no_ng, word_analogies_file)\n",
    "\n",
    "print('Loading Gensim embeddings')\n",
    "text8_gs = Word2Vec.load_word2vec_format(MODELS_DIR + 'text8_gs.vec')\n",
    "print('Accuracy for word2vec:')\n",
    "print_accuracy(text8_gs, word_analogies_file)\n",
    "\n",
    "print('Loading FastText embeddings (with n-grams)')\n",
    "text8_ft = Word2Vec.load_word2vec_format(MODELS_DIR + 'text8_ft.vec')\n",
    "print('Accuracy for FastText (with n-grams):')\n",
    "print_accuracy(text8_ft, word_analogies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the text8 corpus, we observe a similar pattern. Semantic accuracies for all three models are in the same range, while FastText with n-grams performs far better on the syntactic analogies.\n",
    "The semantic accuracy for all models increases significantly with the increase in corpus size. However, the increase in syntactic accuracy from the increase in corpus size for the n-gram FastText model is lower (in both relative and absolute terms) for the n-gram FastText model. This could possibly indicate that advantages gained by incorporating morphological information could be less significant in case of larger corpus sizes (the corpuses used in the original paper seem to indicate this too)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These preliminary results seem to indicate fastText embeddings might be better than word2vec at encoding semantic and especially syntactic information. This is expected, since most syntactic analogies are morphology based, and the char n-gram approach of fastText takes such information into account. It'd be interesting to see how transferable these embeddings are by comparing their performance in a downstream supervised task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] [Enriching Word Vectors with Subword Information](https://arxiv.org/pdf/1607.04606v1.pdf)\n",
    "\n",
    "[2] [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781v3.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
